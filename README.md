# Homography-based loss function for camera pose regression
In this repository, we share our implementation of several camera pose regression
loss functions in a simple end-to-end network similar to
[PoseNet](https://openaccess.thecvf.com/content_iccv_2015/html/Kendall_PoseNet_A_Convolutional_ICCV_2015_paper.html).
We implemented our homography-based loss functions and re-implemented PoseNet, Homoscedastic, Geometric and DSAC loss
functions. We provide the code to train the network and evaluate their performance on the Cambridge dataset.

## Installation

### Dataset setup
Have a look at the [datasets](datasets) folder to setup the Cambridge dataset.

### Python environment setup
We use `python 3.9.7` and `pip 21.2.4`. Modules requirements are listed in [requirements.txt](requirements.txt).
An easy way to setup the python environment is to have [Anaconda](https://www.anaconda.com) installed.  
Setting up an anaconda environment:
```bash
conda create -n homographyloss python=3.9.7 pip=21.2.4
conda activate homographyloss
pip install -r requirements.txt
```

## Run relocalization
The script [main.py](main.py) trains the network on a given scene.
It requires one positional argument: the path to the scene on which to train the model.
For example, for training the model on ShopFacade, simply run:
```bash
python main.py datasets/ShopFacade
```

Other available training options can be listed by running `python main.py -h`.

## Monitor training and test results
Training and test metrics are saved in a `logs` directory. One can monitor them using tensorboard.
Simply run in a new terminal:
```bash
tensorboard --logdir logs
```

All estimated poses are also saved in a CSV file.


## Modified models to take RGB-D input instead of RGB only
We changed the the input layer of the model by adding another channel in the first conv2d layer. Now the model will take 3 channels of the image in addition to the corresponding depth image generated by the depth estimation network. We tried this approach with slight modofications to each one.

1-depth_non_freeze_local_homography.py : is to run the modified model and in the same time updating all the pre-trained weights during the training. The loss function uesd here was the local homography

2-depth_non_freeze_global_homography.py : is to run the modified model and in the same time updating all the pre-trained weights during the training. The loss function uesd here was the global homography

3-depth_non_freeze_local_homography_add_1layer.py : is to run the modified model and in the same time updating all the pre-trained weights during the training. We added a new conv2d layer after the input layer to make the model more complex and able to learn more. The loss function uesd here was the local homography

4-depth_non_freeze_global_homography_add_1layer.py : is to run the modified model and in the same time updating all the pre-trained weights during the training. We added a new conv2d layer after the input layer to make the model more complex and able to learn more. The loss function uesd here was the global homography

5-depth_all_freeze_local_homography.py : is to run the modified model but with freezing all the pre-trained weights during the training except for the weights of the modified input layer. The loss function uesd here was the local homography

6-depth_all_freeze_global_homography.py : is to run the modified model but with freezing all the pre-trained weights during the training except for the weights of the modified input layer. The loss function uesd here was the global homography

7-original_local_homography.py: is to run the original model just to see its performance and compare it with the results of our modified models. The loss function used is local homography 

8-original_global_homography.py: is to run the original model just to see its performance and compare it with the results of our modified models. The loss function used is global homography 
